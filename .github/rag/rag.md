<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# t√¥i s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p g·ªôp chung, h√£y cho t√¥i c·∫•u tr√∫c th∆∞ m·ª•c ƒë·∫ßy ƒë·ªß cho rag

Tuy·ªát! ƒê√¢y l√† c·∫•u tr√∫c th∆∞ m·ª•c ƒë·∫ßy ƒë·ªß cho RAG g·ªôp chung v·ªõi MERN stack, t·ªëi ∆∞u cho ƒë·ªì √°n c·ªßa b·∫°n:

## üóÇÔ∏è C·∫•u tr√∫c Th∆∞ m·ª•c ƒê·∫ßy ƒë·ªß

```
clothing-store/
‚îÇ
‚îú‚îÄ‚îÄ client/                                 # React Frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatWindow.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageList.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatInput.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SizeAdvisorModal.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ProductSuggestions.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ProductDetail.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chatApi.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.tsx
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.ts
‚îÇ
‚îî‚îÄ‚îÄ server/                                 # Node.js Backend (Unified)
    ‚îÇ
    ‚îú‚îÄ‚îÄ config/
    ‚îÇ   ‚îú‚îÄ‚îÄ database.js                     # MongoDB connection
    ‚îÇ   ‚îú‚îÄ‚îÄ pinecone.js                     # Pinecone config
    ‚îÇ   ‚îú‚îÄ‚îÄ openai.js                       # OpenAI config
    ‚îÇ   ‚îî‚îÄ‚îÄ env.js                          # Environment variables
    ‚îÇ
    ‚îú‚îÄ‚îÄ models/                             # Mongoose Models
    ‚îÇ   ‚îú‚îÄ‚îÄ Product.js                      # ‚úÖ Schema b·∫°n ƒë√£ c√≥
    ‚îÇ   ‚îú‚îÄ‚îÄ ProductVariant.js               # ‚úÖ Schema b·∫°n ƒë√£ c√≥
    ‚îÇ   ‚îú‚îÄ‚îÄ Category.js
    ‚îÇ   ‚îú‚îÄ‚îÄ Brand.js
    ‚îÇ   ‚îú‚îÄ‚îÄ Order.js
    ‚îÇ   ‚îú‚îÄ‚îÄ User.js
    ‚îÇ   ‚îú‚îÄ‚îÄ Review.js
    ‚îÇ   ‚îî‚îÄ‚îÄ ChatLog.js                      # üÜï L∆∞u l·ªãch s·ª≠ chat
    ‚îÇ
    ‚îú‚îÄ‚îÄ routes/                             # API Routes
    ‚îÇ   ‚îú‚îÄ‚îÄ products.routes.js              # CRUD products
    ‚îÇ   ‚îú‚îÄ‚îÄ orders.routes.js                # CRUD orders
    ‚îÇ   ‚îú‚îÄ‚îÄ users.routes.js                 # Auth & users
    ‚îÇ   ‚îú‚îÄ‚îÄ chat.routes.js                  # üÜï RAG endpoints
    ‚îÇ   ‚îî‚îÄ‚îÄ index.js                        # Route aggregator
    ‚îÇ
    ‚îú‚îÄ‚îÄ services/                           # Business Logic
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ product.service.js              # Product CRUD logic
    ‚îÇ   ‚îú‚îÄ‚îÄ order.service.js                # Order logic
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ rag/                            # ü§ñ RAG Services (Encapsulated)
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îú‚îÄ‚îÄ core/                       # Core RAG Components
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ RAGService.js           # Main RAG orchestrator
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ VectorStore.js          # Pinecone wrapper
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ LLMProvider.js          # OpenAI wrapper
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îú‚îÄ‚îÄ embeddings/                 # Embedding Services
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ embedding.service.js    # Generate embeddings
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ proposition.service.js  # Chunking logic
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îú‚îÄ‚îÄ retrieval/                  # Retrieval Logic
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ vector-search.service.js
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ reranking.service.js    # Cohere reranking
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îú‚îÄ‚îÄ generation/                 # LLM Generation
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ prompt-builder.js       # CoVe prompts
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ response-generator.js   # Call LLM
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îú‚îÄ‚îÄ orchestrators/              # Intent & Routing
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ intent-classifier.js    # Classify user intent
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ conversation-manager.js # Manage context
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îú‚îÄ‚îÄ specialized/                # Specialized Services
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ size-advisor.service.js # Size recommendations
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ style-matcher.service.js # Outfit suggestions
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ order-lookup.service.js  # Order tracking
    ‚îÇ       ‚îÇ
    ‚îÇ       ‚îî‚îÄ‚îÄ index.js                    # Export all RAG services
    ‚îÇ
    ‚îú‚îÄ‚îÄ scripts/                            # Utility Scripts
    ‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingest-products.js          # Main ingestion script
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ update-single-product.js    # Update 1 product
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clear-index.js              # Clear Pinecone index
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test-rag.js                 # Test RAG quality
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ benchmark.js                # Performance tests
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ migration/
    ‚îÇ       ‚îî‚îÄ‚îÄ migrate-to-pinecone.js      # One-time migration
    ‚îÇ
    ‚îú‚îÄ‚îÄ utils/                              # Shared Utilities
    ‚îÇ   ‚îú‚îÄ‚îÄ logger.js                       # Winston logger
    ‚îÇ   ‚îú‚îÄ‚îÄ errorHandler.js                 # Error middleware
    ‚îÇ   ‚îú‚îÄ‚îÄ validators.js                   # Input validation
    ‚îÇ   ‚îî‚îÄ‚îÄ constants.js                    # Constants
    ‚îÇ
    ‚îú‚îÄ‚îÄ middlewares/                        # Express Middlewares
    ‚îÇ   ‚îú‚îÄ‚îÄ auth.middleware.js              # JWT auth
    ‚îÇ   ‚îú‚îÄ‚îÄ rateLimit.middleware.js         # Rate limiting
    ‚îÇ   ‚îî‚îÄ‚îÄ error.middleware.js             # Error handling
    ‚îÇ
    ‚îú‚îÄ‚îÄ tests/                              # Tests
    ‚îÇ   ‚îú‚îÄ‚îÄ unit/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag/
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ embedding.test.js
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ intent-classifier.test.js
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ integration/
    ‚îÇ       ‚îî‚îÄ‚îÄ chat-flow.test.js
    ‚îÇ
    ‚îú‚îÄ‚îÄ docs/                               # Documentation
    ‚îÇ   ‚îú‚îÄ‚îÄ RAG_ARCHITECTURE.md             # RAG system design
    ‚îÇ   ‚îú‚îÄ‚îÄ API_ENDPOINTS.md                # API documentation
    ‚îÇ   ‚îî‚îÄ‚îÄ DEPLOYMENT.md                   # Deploy guide
    ‚îÇ
    ‚îú‚îÄ‚îÄ .env.example                        # Environment template
    ‚îú‚îÄ‚îÄ .gitignore
    ‚îú‚îÄ‚îÄ package.json
    ‚îî‚îÄ‚îÄ server.js                           # Main entry point
```


***

## üìÅ Chi ti·∫øt t·ª´ng File quan tr·ªçng

### 1. **Main Entry Point**

```javascript
// server/server.js
import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import morgan from 'morgan';
import dotenv from 'dotenv';

// Config
import { connectDatabase } from './config/database.js';
import './config/pinecone.js'; // Initialize Pinecone

// Routes
import routes from './routes/index.js';

// Middlewares
import { errorHandler } from './middlewares/error.middleware.js';
import { rateLimiter } from './middlewares/rateLimit.middleware.js';

dotenv.config();

const app = express();

// Middlewares
app.use(helmet());
app.use(cors());
app.use(morgan('dev'));
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true }));

// Rate limiting
app.use('/api/chat', rateLimiter); // Limit RAG endpoints

// Routes
app.use('/api', routes);

// Health check
app.get('/health', (req, res) => {
  res.json({ 
    status: 'healthy',
    services: {
      mongodb: 'connected',
      pinecone: 'ready'
    }
  });
});

// Error handler (must be last)
app.use(errorHandler);

// Start server
const PORT = process.env.PORT || 3001;

connectDatabase().then(() => {
  app.listen(PORT, () => {
    console.log(`üöÄ Server running on port ${PORT}`);
    console.log(`ü§ñ RAG Service: Active`);
  });
});
```


***

### 2. **Config Files**

```javascript
// server/config/database.js
import mongoose from 'mongoose';

export const connectDatabase = async () => {
  try {
    const conn = await mongoose.connect(process.env.MONGODB_URI, {
      useNewUrlParser: true,
      useUnifiedTopology: true,
    });
    
    console.log(`‚úÖ MongoDB connected: ${conn.connection.host}`);
    return conn;
  } catch (error) {
    console.error('‚ùå MongoDB connection error:', error);
    process.exit(1);
  }
};
```

```javascript
// server/config/pinecone.js
import { Pinecone } from '@pinecone-database/pinecone';

let pineconeClient = null;
let pineconeIndex = null;

export const initializePinecone = async () => {
  if (pineconeClient) return { client: pineconeClient, index: pineconeIndex };

  try {
    pineconeClient = new Pinecone({
      apiKey: process.env.PINECONE_API_KEY,
    });

    pineconeIndex = pineconeClient.Index(process.env.PINECONE_INDEX_NAME || 'clothing-store');

    console.log('‚úÖ Pinecone initialized');
    return { client: pineconeClient, index: pineconeIndex };
  } catch (error) {
    console.error('‚ùå Pinecone initialization error:', error);
    throw error;
  }
};

export const getPineconeIndex = () => {
  if (!pineconeIndex) {
    throw new Error('Pinecone not initialized. Call initializePinecone() first.');
  }
  return pineconeIndex;
};

// Auto-initialize
initializePinecone();
```

```javascript
// server/config/openai.js
import OpenAI from 'openai';

export const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export const MODELS = {
  EMBEDDING: 'text-embedding-3-small',
  CHAT: 'gpt-4o-mini-2024-07-18',
  CHAT_FAST: 'gpt-3.5-turbo',
};
```


***

### 3. **RAG Core Services**

```javascript
// server/services/rag/core/RAGService.js
import { classifyIntent } from '../orchestrators/intent-classifier.js';
import { productAdvice } from '../specialized/product-advisor.service.js';
import { sizeRecommendation } from '../specialized/size-advisor.service.js';
import { orderLookup } from '../specialized/order-lookup.service.js';
import { ConversationManager } from '../orchestrators/conversation-manager.js';

export class RAGService {
  constructor() {
    this.conversationManager = new ConversationManager();
  }

  /**
   * Main chat handler - routes to appropriate service
   */
  async chat(userId, message, conversationHistory = []) {
    try {
      // 1. Classify intent
      const { intent, confidence, extracted_info } = await classifyIntent(message);

      // 2. Get conversation context
      const context = await this.conversationManager.getContext(userId, conversationHistory);

      let result;

      // 3. Route to appropriate service
      switch (intent) {
        case 'product_advice':
          result = await productAdvice(message, context);
          break;

        case 'size_recommendation':
          result = await sizeRecommendation(message, extracted_info, context);
          break;

        case 'style_matching':
          result = await productAdvice(`${message} (ph·ªëi ƒë·ªì)`, context);
          break;

        case 'order_lookup':
          result = await orderLookup(message, extracted_info, userId);
          break;

        default:
          result = {
            answer: "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n‚ú® T∆∞ v·∫•n s·∫£n ph·∫©m\nüìè T∆∞ v·∫•n size\nüé® G·ª£i √Ω ph·ªëi ƒë·ªì\nüì¶ Tra c·ª©u ƒë∆°n h√†ng",
            intent: 'general'
          };
      }

      // 4. Save to conversation history
      await this.conversationManager.addMessage(userId, {
        role: 'user',
        content: message,
        intent,
        timestamp: new Date()
      });

      await this.conversationManager.addMessage(userId, {
        role: 'assistant',
        content: result.answer,
        metadata: result,
        timestamp: new Date()
      });

      return {
        intent,
        confidence,
        ...result,
        conversation_id: context.conversation_id
      };

    } catch (error) {
      console.error('RAGService Error:', error);
      throw error;
    }
  }

  /**
   * Get conversation history for a user
   */
  async getHistory(userId, limit = 20) {
    return this.conversationManager.getHistory(userId, limit);
  }

  /**
   * Clear conversation context
   */
  async clearContext(userId) {
    return this.conversationManager.clearContext(userId);
  }
}
```

```javascript
// server/services/rag/core/VectorStore.js
import { getPineconeIndex } from '../../../config/pinecone.js';
import { getEmbedding } from '../embeddings/embedding.service.js';

export class VectorStore {
  constructor() {
    this.index = getPineconeIndex();
  }

  /**
   * Search vectors by query
   */
  async search(query, options = {}) {
    const {
      topK = 50,
      filter = {},
      includeMetadata = true
    } = options;

    // Generate embedding for query
    const queryVector = await getEmbedding(query);

    // Search in Pinecone
    const results = await this.index.query({
      vector: queryVector,
      topK,
      filter,
      includeMetadata
    });

    return results.matches;
  }

  /**
   * Upsert vectors
   */
  async upsert(vectors) {
    const batchSize = 100;
    const batches = [];

    for (let i = 0; i < vectors.length; i += batchSize) {
      batches.push(vectors.slice(i, i + batchSize));
    }

    for (const batch of batches) {
      await this.index.upsert(batch);
    }

    return { upserted: vectors.length };
  }

  /**
   * Delete vectors by filter
   */
  async delete(filter) {
    await this.index.deleteMany(filter);
    return { deleted: true };
  }

  /**
   * Get vector by ID
   */
  async fetch(ids) {
    return this.index.fetch(ids);
  }
}
```


***

### 4. **Embedding Services**

```javascript
// server/services/rag/embeddings/embedding.service.js
import { openai, MODELS } from '../../../config/openai.js';

/**
 * Generate embedding for text
 * @param {String} text - Text to embed
 * @param {Number} dimensions - Embedding dimensions (default: 1536)
 */
export async function getEmbedding(text, dimensions = 1536) {
  try {
    const response = await openai.embeddings.create({
      model: MODELS.EMBEDDING,
      input: text,
      dimensions,
    });

    return response.data[0].embedding;
  } catch (error) {
    console.error('Embedding Error:', error);
    throw new Error('Failed to generate embedding');
  }
}

/**
 * Batch generate embeddings
 * @param {Array<String>} texts - Array of texts
 */
export async function getBatchEmbeddings(texts, dimensions = 1536) {
  try {
    const response = await openai.embeddings.create({
      model: MODELS.EMBEDDING,
      input: texts,
      dimensions,
    });

    return response.data.map(item => item.embedding);
  } catch (error) {
    console.error('Batch Embedding Error:', error);
    throw new Error('Failed to generate batch embeddings');
  }
}
```

```javascript
// server/services/rag/embeddings/proposition.service.js
import { openai, MODELS } from '../../../config/openai.js';

/**
 * Create propositions from product data
 */
export async function createProductPropositions(product, variants = []) {
  const categoryName = product.category?.name || 'N/A';
  const brandName = product.brand?.name || 'N/A';
  
  const availableSizes = [...new Set(variants.map(v => v.size))];
  const availableColors = [...new Set(variants.map(v => v.color))];
  
  const priceRange = variants.length > 0 
    ? {
        min: Math.min(...variants.map(v => v.price)),
        max: Math.max(...variants.map(v => v.price))
      }
    : null;

  const prompt = `
Ph√¢n t√≠ch s·∫£n ph·∫©m th·ªùi trang sau th√†nh c√°c m·ªánh ƒë·ªÅ nguy√™n t·ª≠, ƒë·ªôc l·∫≠p.

Th√¥ng tin:
- T√™n: ${product.name}
- M√¥ t·∫£: ${product.description}
- Danh m·ª•c: ${categoryName}
- Th∆∞∆°ng hi·ªáu: ${brandName}
- Tags: ${product.tags?.join(', ') || 'N/A'}
- Sizes: ${availableSizes.join(', ')}
- M√†u s·∫Øc: ${availableColors.join(', ')}
- Gi√°: ${priceRange ? `${priceRange.min.toLocaleString()}-${priceRange.max.toLocaleString()} VNƒê` : 'N/A'}

T·∫°o 8-12 m·ªánh ƒë·ªÅ h·ªØu √≠ch cho t∆∞ v·∫•n kh√°ch h√†ng.
Tr·∫£ v·ªÅ JSON: {"propositions": ["...", "..."]}
`;

  const response = await openai.chat.completions.create({
    model: MODELS.CHAT,
    response_format: { type: 'json_object' },
    messages: [{ role: 'user', content: prompt }],
    temperature: 0.3
  });

  const result = JSON.parse(response.choices[0].message.content);
  return result.propositions || [];
}
```


***

### 5. **Retrieval Services**

```javascript
// server/services/rag/retrieval/vector-search.service.js
import { VectorStore } from '../core/VectorStore.js';

const vectorStore = new VectorStore();

/**
 * Search products by semantic similarity
 */
export async function searchProducts(query, options = {}) {
  const filter = {
    type: { $eq: 'product_info' },
    ...options.filter
  };

  const results = await vectorStore.search(query, {
    topK: options.topK || 50,
    filter,
    includeMetadata: true
  });

  return results;
}

/**
 * Search by category
 */
export async function searchByCategory(query, categoryName) {
  return searchProducts(query, {
    filter: { category: { $eq: categoryName } }
  });
}

/**
 * Search in-stock products
 */
export async function searchInStock(query) {
  return searchProducts(query, {
    filter: { in_stock: { $eq: true } }
  });
}
```

```javascript
// server/services/rag/retrieval/reranking.service.js
import { CohereClient } from 'cohere-ai';

const cohere = new CohereClient({
  token: process.env.COHERE_API_KEY
});

/**
 * Rerank documents using Cohere
 */
export async function rerankDocuments(query, documents, topN = 5) {
  try {
    if (!process.env.COHERE_API_KEY) {
      console.warn('‚ö†Ô∏è Cohere API key not found. Skipping reranking.');
      return documents.slice(0, topN).map((doc, index) => ({
        index,
        relevance_score: 1.0 - (index * 0.1),
        document: doc
      }));
    }

    const response = await cohere.rerank({
      model: 'rerank-multilingual-v3.0',
      query,
      documents,
      topN,
      returnDocuments: false
    });

    return response.results;
  } catch (error) {
    console.error('Reranking Error:', error);
    // Fallback: return top N without reranking
    return documents.slice(0, topN).map((doc, index) => ({
      index,
      relevance_score: 1.0,
      document: doc
    }));
  }
}
```


***

### 6. **Generation Services**

```javascript
// server/services/rag/generation/prompt-builder.js

/**
 * Build CoVe (Chain of Verification) prompt
 */
export function buildCoVePrompt(context, conversationHistory = []) {
  return `
B·∫°n l√† chuy√™n gia t∆∞ v·∫•n th·ªùi trang c·ªßa c·ª≠a h√†ng qu·∫ßn √°o online.

## Nguy√™n t·∫Øc:
- CH·ªà s·ª≠ d·ª•ng th√¥ng tin t·ª´ [Context]
- KH√îNG b·ªãa ƒë·∫∑t th√¥ng tin
- N·∫øu kh√¥ng bi·∫øt, n√≥i: "T√¥i c·∫ßn ki·ªÉm tra l·∫°i"

## Quy tr√¨nh (Chain of Verification):
1. **Draft**: Vi·∫øt b·∫£n nh√°p t·ª´ context
2. **Verify**: Ki·ªÉm tra 2-3 chi ti·∫øt:
   - Size c√≥ ƒë√∫ng?
   - Gi√° c√≥ ch√≠nh x√°c?
   - M√†u s·∫Øc c√≥ kh·ªõp?
3. **Final**: C√¢u tr·∫£ l·ªùi cu·ªëi sau khi x√°c minh

## H∆∞·ªõng d·∫´n:

### T∆∞ v·∫•n Size:
- H·ªèi: chi·ªÅu cao, c√¢n n·∫∑ng
- ƒê·ªÅ xu·∫•t size d·ª±a tr√™n context
- Gi·∫£i th√≠ch l√Ω do

### T∆∞ v·∫•n Ph·ªëi ƒë·ªì:
- Xem category, tags, m√†u
- ƒê·ªÅ xu·∫•t combo t·ª´ products c√≥ s·∫µn
- Gi·∫£i th√≠ch style

### Format:
- Th√¢n thi·ªán, chuy√™n nghi·ªáp
- D√πng emoji ph√π h·ª£p üëï ‚ú®
- K·∫øt th√∫c = c√¢u h·ªèi m·ªü

[Context]
${context}
[End Context]
`;
}

/**
 * Build system prompt for intent classification
 */
export function buildIntentClassificationPrompt() {
  return `
Ph√¢n lo·∫°i √Ω ƒë·ªãnh kh√°ch h√†ng:

**Intents:**
- "product_advice": T∆∞ v·∫•n s·∫£n ph·∫©m, t√¨m qu·∫ßn √°o
- "size_recommendation": H·ªèi v·ªÅ size, s·ªë ƒëo
- "style_matching": Ph·ªëi ƒë·ªì, mix & match
- "order_lookup": Tra ƒë∆°n h√†ng, v·∫≠n chuy·ªÉn
- "return_exchange": ƒê·ªïi tr·∫£, ho√†n ti·ªÅn
- "general": Kh√°c

Tr·∫£ v·ªÅ: {"intent": "...", "confidence": 0.0-1.0, "extracted_info": {...}}
`;
}
```

```javascript
// server/services/rag/generation/response-generator.js
import { openai, MODELS } from '../../../config/openai.js';
import { buildCoVePrompt } from './prompt-builder.js';

/**
 * Generate response using LLM
 */
export async function generateResponse(query, context, conversationHistory = []) {
  const systemPrompt = buildCoVePrompt(context, conversationHistory);

  const messages = [
    { role: 'system', content: systemPrompt },
    ...conversationHistory.slice(-4), // Last 4 messages
    { role: 'user', content: query }
  ];

  try {
    const response = await openai.chat.completions.create({
      model: MODELS.CHAT,
      messages,
      temperature: 0.3,
      max_tokens: 800,
      presence_penalty: 0.1,
      frequency_penalty: 0.1
    });

    return response.choices[0].message.content;
  } catch (error) {
    console.error('LLM Generation Error:', error);
    throw new Error('Failed to generate response');
  }
}
```


***

### 7. **Orchestrators**

```javascript
// server/services/rag/orchestrators/intent-classifier.js
import { openai, MODELS } from '../../../config/openai.js';
import { buildIntentClassificationPrompt } from '../generation/prompt-builder.js';

/**
 * Classify user intent
 */
export async function classifyIntent(message) {
  const systemPrompt = buildIntentClassificationPrompt();

  try {
    const response = await openai.chat.completions.create({
      model: MODELS.CHAT_FAST, // Use faster model for classification
      response_format: { type: 'json_object' },
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: message }
      ],
      temperature: 0.1
    });

    const result = JSON.parse(response.choices[0].message.content);
    
    return {
      intent: result.intent || 'general',
      confidence: result.confidence || 0.5,
      extracted_info: result.extracted_info || {}
    };
  } catch (error) {
    console.error('Intent Classification Error:', error);
    return {
      intent: 'general',
      confidence: 0,
      extracted_info: {}
    };
  }
}
```

```javascript
// server/services/rag/orchestrators/conversation-manager.js
import ChatLog from '../../../models/ChatLog.js';

export class ConversationManager {
  /**
   * Get conversation context for user
   */
  async getContext(userId, recentMessages = []) {
    // Get recent chat history from DB
    const history = await ChatLog.find({ user_id: userId })
      .sort({ created_at: -1 })
      .limit(10)
      .lean();

    return {
      conversation_id: userId,
      history: history.reverse(),
      recent_messages: recentMessages
    };
  }

  /**
   * Add message to conversation
   */
  async addMessage(userId, message) {
    const chatLog = await ChatLog.create({
      user_id: userId,
      role: message.role,
      content: message.content,
      intent: message.intent,
      metadata: message.metadata,
      created_at: message.timestamp
    });

    return chatLog;
  }

  /**
   * Get conversation history
   */
  async getHistory(userId, limit = 20) {
    return ChatLog.find({ user_id: userId })
      .sort({ created_at: -1 })
      .limit(limit)
      .lean();
  }

  /**
   * Clear conversation context
   */
  async clearContext(userId) {
    await ChatLog.deleteMany({ user_id: userId });
    return { cleared: true };
  }
}
```


***

### 8. **Specialized Services**

```javascript
// server/services/rag/specialized/product-advisor.service.js
import Product from '../../../models/Product.js';
import ProductVariant from '../../../models/ProductVariant.js';
import { searchProducts } from '../retrieval/vector-search.service.js';
import { rerankDocuments } from '../retrieval/reranking.service.js';
import { generateResponse } from '../generation/response-generator.js';

/**
 * Product advice using RAG
 */
export async function productAdvice(query, context = {}) {
  try {
    // 1. Vector search
    const searchResults = await searchProducts(query, { topK: 50 });

    if (searchResults.length === 0) {
      return {
        answer: "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p. B·∫°n c√≥ th·ªÉ m√¥ t·∫£ chi ti·∫øt h∆°n?",
        sources: []
      };
    }

    // 2. Rerank
    const documents = searchResults.map(r => r.metadata.proposition_text);
    const reranked = await rerankDocuments(query, documents, 5);

    // 3. Get product details from MongoDB
    const productIds = [
      ...new Set(
        reranked.map(r => searchResults[r.index].metadata.product_id)
      )
    ];

    const products = await Product.find({ _id: { $in: productIds } })
      .populate('category brand')
      .lean();

    const productsWithVariants = await Promise.all(
      products.map(async (product) => {
        const variants = await ProductVariant.find({
          product_id: product._id,
          isActive: true,
          quantity: { $gt: 0 }
        }).lean();
        return { ...product, variants };
      })
    );

    // 4. Build context
    let contextText = "## S·∫£n ph·∫©m li√™n quan:\n\n";
    
    reranked.forEach((r, idx) => {
      const match = searchResults[r.index];
      const product = productsWithVariants.find(
        p => p._id.toString() === match.metadata.product_id
      );

      if (product) {
        contextText += `### ${idx + 1}. ${product.name}\n`;
        contextText += `- Danh m·ª•c: ${product.category?.name}\n`;
        contextText += `- M√¥ t·∫£: ${product.description.substring(0, 200)}...\n`;
        
        if (product.variants.length > 0) {
          const sizes = [...new Set(product.variants.map(v => v.size))];
          const colors = [...new Set(product.variants.map(v => v.color))];
          const prices = product.variants.map(v => v.price);
          
          contextText += `- Sizes: ${sizes.join(', ')}\n`;
          contextText += `- M√†u: ${colors.join(', ')}\n`;
          contextText += `- Gi√°: ${Math.min(...prices).toLocaleString()}-${Math.max(...prices).toLocaleString()}ƒë\n`;
        }
        
        contextText += `\n`;
      }
    });

    // 5. Generate response
    const answer = await generateResponse(query, contextText, context.recent_messages);

    // 6. Return result
    return {
      answer,
      sources: reranked.map(r => {
        const match = searchResults[r.index];
        const product = productsWithVariants.find(
          p => p._id.toString() === match.metadata.product_id
        );
        
        return {
          product_id: match.metadata.product_id,
          product_name: match.metadata.product_name,
          relevance_score: r.relevance_score,
          url_slug: product?.urlSlug,
        };
      }),
      suggested_products: productsWithVariants.slice(0, 3).map(p => ({
        _id: p._id,
        name: p.name,
        urlSlug: p.urlSlug,
        averageRating: p.averageRating,
        minPrice: p.variants.length > 0 ? Math.min(...p.variants.map(v => v.price)) : 0,
        mainImage: p.variants[0]?.mainImage || ''
      }))
    };

  } catch (error) {
    console.error('Product Advice Error:', error);
    throw error;
  }
}
```

```javascript
// server/services/rag/specialized/size-advisor.service.js
import { openai, MODELS } from '../../../config/openai.js';
import Product from '../../../models/Product.js';
import ProductVariant from '../../../models/ProductVariant.js';

/**
 * Size recommendation service
 */
export async function sizeRecommendation(query, extractedInfo, context) {
  // Extract product info from query or context
  const productId = extractedInfo.product_id || context.recent_product_id;

  if (!productId) {
    return {
      answer: "ƒê·ªÉ t∆∞ v·∫•n size, b·∫°n vui l√≤ng cho bi·∫øt:\n- S·∫£n ph·∫©m b·∫°n quan t√¢m\n- Chi·ªÅu cao (cm)\n- C√¢n n·∫∑ng (kg) üìè"
    };
  }

  const product = await Product.findById(productId).populate('category').lean();
  const variants = await ProductVariant.find({
    product_id: productId,
    isActive: true,
    quantity: { $gt: 0 }
  }).lean();

  const availableSizes = [...new Set(variants.map(v => v.size))];

  // Build prompt for size recommendation
  const prompt = `
T∆∞ v·∫•n size cho s·∫£n ph·∫©m:

**S·∫£n ph·∫©m:** ${product.name}
**Danh m·ª•c:** ${product.category.name}
**Sizes c√≥ s·∫µn:** ${availableSizes.join(', ')}

**C√¢u h·ªèi kh√°ch h√†ng:** ${query}

D·ª±a v√†o th√¥ng tin, h√£y:
1. ƒê·ªÅ xu·∫•t size (CH·ªà t·ª´ sizes c√≥ s·∫µn)
2. Gi·∫£i th√≠ch l√Ω do
3. G·ª£i √Ω size d·ª± ph√≤ng

Tr·∫£ v·ªÅ JSON: 
{
  "recommended_size": "...",
  "reason": "...",
  "alternative_size": "...",
  "fit_note": "..."
}
`;

  const response = await openai.chat.completions.create({
    model: MODELS.CHAT,
    response_format: { type: 'json_object' },
    messages: [{ role: 'user', content: prompt }],
    temperature: 0.2
  });

  const result = JSON.parse(response.choices[0].message.content);

  // Get variants of recommended size
  const recommendedVariants = variants.filter(v => v.size === result.recommended_size);

  return {
    answer: `
üìè **Size ƒë·ªÅ xu·∫•t: ${result.recommended_size}**

${result.reason}

üí° ${result.fit_note}

${result.alternative_size ? `‚ú® Size d·ª± ph√≤ng: ${result.alternative_size}` : ''}

**S·∫£n ph·∫©m c√≥ s·∫µn:**
${recommendedVariants.map(v => 
  `- M√†u ${v.color}: ${v.price.toLocaleString()}ƒë (C√≤n ${v.quantity})`
).join('\n')}
    `.trim(),
    size_recommendation: result,
    available_variants: recommendedVariants
  };
}
```

```javascript
// server/services/rag/specialized/order-lookup.service.js
import { openai, MODELS } from '../../../config/openai.js';
import Order from '../../../models/Order.js';

/**
 * Order lookup service
 */
export async function orderLookup(query, extractedInfo, userId) {
  // Extract order info
  const extractPrompt = `
Tr√≠ch xu·∫•t th√¥ng tin tra c·ª©u ƒë∆°n h√†ng:

C√¢u h·ªèi: ${query}

Tr·∫£ v·ªÅ JSON: {"order_number": "...", "phone": "...", "email": "..."}
`;

  const extractResponse = await openai.chat.completions.create({
    model: MODELS.CHAT_FAST,
    response_format: { type: 'json_object' },
    messages: [{ role: 'user', content: extractPrompt }]
  });

  const extracted = JSON.parse(extractResponse.choices[0].message.content);

  // Query MongoDB
  const order = await Order.findOne({
    $or: [
      { order_number: extracted.order_number },
      { user_id: userId }
    ]
  })
    .sort({ created_at: -1 })
    .lean();

  if (!order) {
    return {
      answer: "‚ùå Kh√¥ng t√¨m th·∫•y ƒë∆°n h√†ng. Vui l√≤ng ki·ªÉm tra l·∫°i m√£ ƒë∆°n ho·∫∑c li√™n h·ªá hotline."
    };
  }

  return {
    answer: `
üì¶ **ƒê∆°n h√†ng ${order.order_number}**

‚úÖ Tr·∫°ng th√°i: ${order.status}
üöö M√£ v·∫≠n ƒë∆°n: ${order.tracking_number || 'ƒêang chu·∫©n b·ªã'}
üìÖ Ng√†y ƒë·∫∑t: ${new Date(order.created_at).toLocaleDateString('vi-VN')}
üí∞ T·ªïng ti·ªÅn: ${order.total_amount.toLocaleString()}ƒë

${order.status === 'processing' ? '‚è≥ ƒê∆°n h√†ng ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω' : ''}
${order.status === 'shipped' ? 'üöÄ ƒê∆°n h√†ng ƒë√£ g·ª≠i ƒëi' : ''}
${order.status === 'delivered' ? '‚ú® ƒê∆°n h√†ng ƒë√£ giao th√†nh c√¥ng' : ''}
    `.trim(),
    order_info: order
  };
}
```


***

### 9. **Index File (Export t·∫•t c·∫£)**

```javascript
// server/services/rag/index.js
export { RAGService } from './core/RAGService.js';
export { VectorStore } from './core/VectorStore.js';

export { getEmbedding, getBatchEmbeddings } from './embeddings/embedding.service.js';
export { createProductPropositions } from './embeddings/proposition.service.js';

export { searchProducts, searchByCategory, searchInStock } from './retrieval/vector-search.service.js';
export { rerankDocuments } from './retrieval/reranking.service.js';

export { generateResponse } from './generation/response-generator.js';
export { buildCoVePrompt, buildIntentClassificationPrompt } from './generation/prompt-builder.js';

export { classifyIntent } from './orchestrators/intent-classifier.js';
export { ConversationManager } from './orchestrators/conversation-manager.js';

export { productAdvice } from './specialized/product-advisor.service.js';
export { sizeRecommendation } from './specialized/size-advisor.service.js';
export { orderLookup } from './specialized/order-lookup.service.js';
```


***

### 10. **Routes**

```javascript
// server/routes/chat.routes.js
import express from 'express';
import { RAGService } from '../services/rag/index.js';
import { authenticate } from '../middlewares/auth.middleware.js';
import ChatLog from '../models/ChatLog.js';

const router = express.Router();
const ragService = new RAGService();

/**
 * POST /api/chat
 * Main chat endpoint
 */
router.post('/', authenticate, async (req, res) => {
  try {
    const { message, conversation_history = [] } = req.body;
    const userId = req.user?.id || 'anonymous';

    if (!message || message.trim().length === 0) {
      return res.status(400).json({ error: 'Message is required' });
    }

    // Call RAG service
    const result = await ragService.chat(userId, message, conversation_history);

    res.json({
      success: true,
      ...result,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('Chat Route Error:', error);
    res.status(500).json({
      success: false,
      error: 'ƒê√£ c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i.',
      details: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

/**
 * GET /api/chat/history
 * Get conversation history
 */
router.get('/history', authenticate, async (req, res) => {
  try {
    const userId = req.user.id;
    const limit = parseInt(req.query.limit) || 20;

    const history = await ragService.getHistory(userId, limit);

    res.json({
      success: true,
      history
    });

  } catch (error) {
    console.error('History Route Error:', error);
    res.status(500).json({ error: error.message });
  }
});

/**
 * DELETE /api/chat/clear
 * Clear conversation context
 */
router.delete('/clear', authenticate, async (req, res) => {
  try {
    const userId = req.user.id;
    await ragService.clearContext(userId);

    res.json({
      success: true,
      message: 'Conversation cleared'
    });

  } catch (error) {
    console.error('Clear Route Error:', error);
    res.status(500).json({ error: error.message });
  }
});

export default router;
```

```javascript
// server/routes/index.js
import express from 'express';
import productRoutes from './products.routes.js';
import orderRoutes from './orders.routes.js';
import userRoutes from './users.routes.js';
import chatRoutes from './chat.routes.js';

const router = express.Router();

// Traditional CRUD routes
router.use('/products', productRoutes);
router.use('/orders', orderRoutes);
router.use('/users', userRoutes);

// RAG routes
router.use('/chat', chatRoutes);

export default router;
```


***

### 11. **Models**

```javascript
// server/models/ChatLog.js
import mongoose from 'mongoose';

const chatLogSchema = new mongoose.Schema(
  {
    user_id: {
      type: String,
      required: true,
      index: true
    },
    role: {
      type: String,
      enum: ['user', 'assistant', 'system'],
      required: true
    },
    content: {
      type: String,
      required: true
    },
    intent: {
      type: String,
      enum: ['product_advice', 'size_recommendation', 'style_matching', 'order_lookup', 'return_exchange', 'general']
    },
    metadata: {
      type: mongoose.Schema.Types.Mixed,
      default: {}
    },
    created_at: {
      type: Date,
      default: Date.now,
      index: true
    }
  },
  {
    timestamps: false
  }
);

// Index for efficient queries
chatLogSchema.index({ user_id: 1, created_at: -1 });

const ChatLog = mongoose.model('ChatLog', chatLogSchema);

export default ChatLog;
```


***

### 12. **Ingestion Script**

```javascript
// server/scripts/ingestion/ingest-products.js
import mongoose from 'mongoose';
import dotenv from 'dotenv';
import Product from '../../models/Product.js';
import ProductVariant from '../../models/ProductVariant.js';
import { VectorStore } from '../../services/rag/core/VectorStore.js';
import { createProductPropositions } from '../../services/rag/embeddings/proposition.service.js';
import { getEmbedding } from '../../services/rag/embeddings/embedding.service.js';
import { initializePinecone } from '../../config/pinecone.js';

dotenv.config();

const vectorStore = new VectorStore();

async function ingestAllProducts() {
  try {
    // Connect to MongoDB
    await mongoose.connect(process.env.MONGODB_URI);
    console.log('‚úÖ MongoDB connected');

    // Initialize Pinecone
    await initializePinecone();
    console.log('‚úÖ Pinecone initialized');

    // Get all active products
    const products = await Product.find({
      isActive: true,
      status: 'published'
    })
      .populate('category brand')
      .lean();

    console.log(`üì¶ Found ${products.length} products to ingest\n`);

    let totalVectors = 0;

    for (const product of products) {
      console.log(`Processing: ${product.name}`);

      // Get variants
      const variants = await ProductVariant.find({
        product_id: product._id,
        isActive: true
      }).lean();

      // Create propositions
      const propositions = await createProductPropositions(product, variants);
      console.log(`  ‚îî‚îÄ Generated ${propositions.length} propositions`);

      // Prepare vectors
      const vectors = [];

      for (let i = 0; i < propositions.length; i++) {
        const propText = propositions[i];
        const embedding = await getEmbedding(propText);

        vectors.push({
          id: `prod_${product._id}_prop_${i}`,
          values: embedding,
          metadata: {
            type: 'product_info',
            product_id: product._id.toString(),
            product_name: product.name,
            category: product.category?.name || 'N/A',
            brand: product.brand?.name || 'N/A',
            tags: product.tags || [],
            average_rating: product.averageRating || 0,
            proposition_text: propText,
            url_slug: product.urlSlug || ''
          }
        });
      }

      // Variant info vector
      if (variants.length > 0) {
        const sizeColorInfo = `${product.name} c√≥ sizes ${[...new Set(variants.map(v => v.size))].join(', ')} v√† m√†u ${[...new Set(variants.map(v => v.color))].join(', ')}`;
        const sizeColorEmbedding = await getEmbedding(sizeColorInfo);

        vectors.push({
          id: `prod_${product._id}_variants_info`,
          values: sizeColorEmbedding,
          metadata: {
            type: 'variant_info',
            product_id: product._id.toString(),
            product_name: product.name,
            available_sizes: [...new Set(variants.map(v => v.size))],
            available_colors: [...new Set(variants.map(v => v.color))],
            in_stock: variants.some(v => v.quantity > 0),
            min_price: Math.min(...variants.map(v => v.price)),
            max_price: Math.max(...variants.map(v => v.price)),
            proposition_text: sizeColorInfo
          }
        });
      }

      // Upsert to Pinecone
      await vectorStore.upsert(vectors);
      console.log(`  ‚úÖ Upserted ${vectors.length} vectors\n`);

      totalVectors += vectors.length;

      // Delay to avoid rate limit
      await new Promise(resolve => setTimeout(resolve, 200));
    }

    console.log(`\nüéâ Ingestion completed!`);
    console.log(`üìä Total vectors: ${totalVectors}`);

  } catch (error) {
    console.error('‚ùå Ingestion Error:', error);
  } finally {
    await mongoose.disconnect();
    console.log('üëã Disconnected from MongoDB');
  }
}

// Run
ingestAllProducts();
```


***

### 13. **Environment Variables**

```bash
# server/.env.example

# Server
NODE_ENV=development
PORT=3001

# MongoDB
MONGODB_URI=mongodb://localhost:27017/clothing-store

# Pinecone
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=clothing-store

# OpenAI
OPENAI_API_KEY=your_openai_api_key

# Cohere (Optional - for reranking)
COHERE_API_KEY=your_cohere_api_key

# JWT
JWT_SECRET=your_jwt_secret
JWT_EXPIRE=7d
```


***

### 14. **Package.json Scripts**

```json
{
  "name": "clothing-store-server",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "nodemon server.js",
    "start": "node server.js",
    "ingest": "node scripts/ingestion/ingest-products.js",
    "test": "jest",
    "test:rag": "node scripts/evaluation/test-rag.js"
  },
  "dependencies": {
    "@pinecone-database/pinecone": "^2.0.0",
    "cohere-ai": "^7.0.0",
    "cors": "^2.8.5",
    "dotenv": "^16.0.3",
    "express": "^4.18.2",
    "helmet": "^7.1.0",
    "jsonwebtoken": "^9.0.2",
    "mongoose": "^8.0.0",
    "morgan": "^1.10.0",
    "openai": "^4.20.0",
    "winston": "^3.11.0"
  },
  "devDependencies": {
    "nodemon": "^3.0.2",
    "jest": "^29.7.0"
  }
}
```


***

## üéØ T√≥m t·∫Øt Ki·∫øn tr√∫c

‚úÖ **Encapsulation**: T·∫•t c·∫£ RAG logic n·∫±m trong `services/rag/`
‚úÖ **Modularity**: M·ªói service c√≥ tr√°ch nhi·ªám r√µ r√†ng
‚úÖ **Scalability**: D·ªÖ d√†ng th√™m t√≠nh nƒÉng m·ªõi (th√™m service trong `specialized/`)
‚úÖ **Maintainability**: Code organized, d·ªÖ debug
‚úÖ **Future-proof**: S·∫µn s√†ng t√°ch th√†nh microservice n·∫øu c·∫ßn


