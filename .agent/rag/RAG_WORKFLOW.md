# RAG System Workflow - Devenir Fashion AI

TÃ i liá»‡u nÃ y mÃ´ táº£ chi tiáº¿t workflow cá»§a há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) Ä‘á»ƒ tÆ° váº¥n sáº£n pháº©m, size vÃ  há»— trá»£ khÃ¡ch hÃ ng.

---

## Kiáº¿n trÃºc Tá»•ng quan

```mermaid
flowchart TB
    subgraph Client["ðŸ–¥ï¸ Client"]
        CW[ChatWindow.jsx]
        CM[ChatMessage.jsx]
    end
    
    subgraph API["ðŸ”Œ API Layer"]
        CR[chatRoutes.js]
    end
    
    subgraph Core["âš™ï¸ Core"]
        RS[RAGService.js]
        LP[LLMProvider.js]
        ConvMgr[conversation-manager.js]
    end
    
    subgraph Orchestrators["ðŸŽ›ï¸ Orchestrators"]
        IC[intent-classifier.js]
        HCI[hybridClassifyIntent]
        QID[quickIntentDetection]
    end
    
    subgraph Specialized["ðŸŽ¯ Specialized Services"]
        PA[product-advisor.service.js]
        SA[size-advisor.service.js]
        OL[order-lookup.service.js]
        SM[style-matcher.service.js]
        PF[policy-faq.service.js]
        AC[add-to-cart.service.js]
    end
    
    subgraph Retrieval["ðŸ” Retrieval"]
        VS[vector-search.service.js]
        RR[reranking.service.js]
    end
    
    subgraph Generation["âœ¨ Generation"]
        RG[response-generator.js]
        PB[prompt-builder.js]
    end
    
    subgraph External["â˜ï¸ External Services"]
        OAI[OpenAI API]
        PC[Pinecone]
        CO[Cohere Rerank]
    end
    
    CW --> CR
    CR --> RS
    RS --> IC
    RS --> ConvMgr
    IC --> HCI
    HCI --> QID
    HCI --> LP
    IC --> PA
    IC --> SA
    IC --> OL
    IC --> SM
    IC --> PF
    IC --> AC
    PA --> VS
    PA --> RR
    PA --> RG
    SA --> VS
    RG --> PB
    LP --> OAI
    VS --> PC
    RR --> CO
```

---

## Luá»“ng xá»­ lÃ½ chi tiáº¿t

### 1ï¸âƒ£ User gá»­i tin nháº¯n

```
User: "tÃ¬m Ã¡o polo mÃ u tráº¯ng"
     â†“
ChatWindow.jsx â†’ POST /api/chat
     â†“
chatRoutes.js â†’ RAGService.chat(userId, message, history)
```

### 2ï¸âƒ£ PhÃ¢n loáº¡i Intent (Hybrid Approach)

```javascript
// intent-classifier.js
hybridClassifyIntent(message, conversationHistory)
     â†“
1. quickIntentDetection() - Keyword-based (fast)
   - "policy_faq" + confidence >= 0.7 â†’ Return immediately
   - "add_to_cart" + confidence >= 0.8 â†’ Return immediately
     â†“
2. classifyIntent() - LLM-based (accurate)
   - Uses conversation history for context
   - Returns JSON: { intent, confidence, extracted_info }
     â†“
3. Compare & decide
   - If LLM confidence < 0.6 â†’ Use keyword result
   - Otherwise â†’ Use LLM result
```

**Intent Types:**

| Intent | MÃ´ táº£ | Trigger Keywords |
|--------|-------|------------------|
| `product_advice` | TÆ° váº¥n sáº£n pháº©m | tÃ¬m, muá»‘n, cáº§n, gá»£i Ã½, sáº£n pháº©m |
| `size_recommendation` | TÆ° váº¥n size | size, chiá»u cao, cÃ¢n náº·ng, form |
| `style_matching` | Phá»‘i Ä‘á»“ | phá»‘i, mix, match, outfit |
| `order_lookup` | Tra cá»©u Ä‘Æ¡n hÃ ng | Ä‘Æ¡n hÃ ng, tracking, theo dÃµi |
| `policy_faq` | ChÃ­nh sÃ¡ch | payment, shipping, Ä‘á»•i tráº£ |
| `add_to_cart` | ThÃªm vÃ o giá» | thÃªm vÃ o bag, add to cart, mua |
| `general` | Chung | (fallback) |

### 3ï¸âƒ£ Parallel Processing

```javascript
// RAGService.js - Tá»‘i Æ°u performance
const [intentResult, context] = await Promise.all([
    hybridClassifyIntent(message, conversationHistory),
    conversationManager.getContext(userId, conversationHistory)
]);
```

### 4ï¸âƒ£ Route Ä‘áº¿n Service phÃ¹ há»£p

```javascript
// RAGService.js
switch (intent) {
    case 'product_advice':    â†’ productAdvice(message, context)
    case 'size_recommendation': â†’ sizeRecommendation(message, extracted_info, context)
    case 'style_matching':    â†’ styleMatcher(message, context)
    case 'order_lookup':      â†’ orderLookup(message, extracted_info, userId)
    case 'policy_faq':        â†’ policyFAQ(message, extracted_info)
    case 'add_to_cart':       â†’ handleAddToCart(message, extracted_info, context)
    default:                  â†’ General help message
}
```

---

## Chi tiáº¿t tá»«ng Module

### ðŸ“ **core/**

| File | Chá»©c nÄƒng |
|------|-----------|
| `RAGService.js` | Entry point - Ä‘iá»u phá»‘i toÃ n bá»™ flow, parallel processing |
| `VectorStore.js` | Káº¿t ná»‘i Pinecone vector database |
| `LLMProvider.js` | Wrapper cho OpenAI API vá»›i cÃ¡c methods: `chatCompletion()`, `jsonCompletion()`, `fastCompletion()`, `embed()` |

**LLMProvider Methods:**

```javascript
// Chat completion (GPT-4o-mini)
await llmProvider.chatCompletion(messages, { temperature: 0.3, maxTokens: 800 })

// JSON response (fast model)
await llmProvider.jsonCompletion(messages, { temperature: 0.1 })

// Embeddings (3-small, 1536 dimensions)
await llmProvider.embed(text)
await llmProvider.embedBatch(texts)
```

---

### ðŸ“ **orchestrators/**

| File | Chá»©c nÄƒng |
|------|-----------|
| `intent-classifier.js` | Hybrid classification: Keyword fallback + LLM |
| `conversation-manager.js` | Quáº£n lÃ½ context há»™i thoáº¡i, lÆ°u ChatLog vÃ o MongoDB |

**Keyword-based Intent Detection:**

```javascript
quickIntentDetection(message)
// Returns: { intent: 'product_advice', confidence: 0.6 }

// Priority keywords (bypass LLM):
- policy_faq: payment, shipping, crypto, payos, nowpayments
- add_to_cart: thÃªm vÃ o bag, add to cart, mua ngay
```

---

### ðŸ“ **specialized/**

#### 1. `product-advisor.service.js`

**Flow: Vector Search â†’ Color Filter â†’ Rerank â†’ Generate**

```javascript
async productAdvice(query, context) {
    // 1. Enrich short queries with conversation context
    // 2. Vector search (Pinecone, topK: 50)
    // 3. Color detection (VI â†’ EN mapping)
    // 4. MongoDB query for color variants
    // 5. Rerank vá»›i Cohere (dÃ¹ng **Enriched Query** Ä‘á»ƒ giá»¯ context sáº£n pháº©m, top 10)
    // 6. Build context text
    // 7. Generate response (OpenAI)
    // 8. Return: { answer, sources, suggested_products }
}
```

**Color Detection:**

```javascript
// Vietnamese â†’ English mapping
VI_TO_EN_COLORS = {
    'tráº¯ng': 'white',
    'Ä‘en': 'black',
    'Ä‘á» rÆ°á»£u': 'wine red',
    ...
}

// Compound colors support
COMPOUND_COLORS = ['wine red', 'navy blue', 'dusty pink', ...]
```

#### 2. `size-advisor.service.js`

**Flow: Product Lookup â†’ Size Chart â†’ LLM Recommendation**

```javascript
async sizeRecommendation(query, extractedInfo, context) {
    // 1. Get product from context or vector search
    // 2. Check Free Size / One Size
    // 3. Build size chart prompt
    // 4. LLM generates recommendation (JSON)
    // 5. Return: { answer, size_recommendation, suggested_action }
}
```

**Size Chart (Hardcoded):**

```
XS:   < 1m60, < 50kg
S:    1m60 - 1m65, 50 - 60kg
M:    1m65 - 1m70, 60 - 70kg
L:    1m70 - 1m75, 70 - 80kg
XL:   1m75 - 1m80, 80 - 90kg
XXL:  1m80 - 1m85, 90 - 100kg
```

**Suggested Action (Add to Cart Button):**

```javascript
suggested_action: {
    type: 'add_to_cart',
    prompt: 'Báº¡n cÃ³ muá»‘n thÃªm sáº£n pháº©m nÃ y vÃ o giá» hÃ ng khÃ´ng?',
    product: { _id, name, variantId, mainImage, price },
    variant_id: '...'
}
```

#### 3. `order-lookup.service.js`

**Flow: Query Classification â†’ Order Search â†’ Format Response**

```javascript
async orderLookup(query, extractedInfo, userId) {
    // 1. LLM classify query type: list_all | specific | latest
    // 2. Route to handler:
    //    - list_all â†’ handleListAllOrders(userId)
    //    - latest â†’ handleLatestOrder(userId)
    //    - specific â†’ handleSpecificOrder({ order_number, phone, email })
    // 3. Format order details with status translation
}
```

**Order Status Translation:**

```javascript
statusMap = {
    'pending': 'Chá» thanh toÃ¡n',
    'paid': 'ÄÃ£ thanh toÃ¡n',
    'shipped': 'Äang giao hÃ ng',
    'delivered': 'ÄÃ£ giao thÃ nh cÃ´ng',
    'cancelled': 'ÄÃ£ há»§y'
}
```

#### 4. `policy-faq.service.js`

**Flow: Keyword Detection â†’ Static Response**

```javascript
async policyFAQ(query, extractedInfo) {
    // No LLM needed - uses hardcoded policy info
    
    PAYMENT_INFO = {
        methods: ['PayOS', 'NowPayments (Crypto)']
    }
    
    SHIPPING_INFO = {
        options: [
            { name: 'Standard', price: 'FREE', time: '2-3 ngÃ y' },
            { name: 'Next day', price: '$5', time: '1 ngÃ y' },
            { name: 'Nominated', price: '$10', time: 'Chá»n ngÃ y' }
        ]
    }
    
    RETURN_POLICY = {
        period: '30 ngÃ y',
        conditions: ['ChÆ°a sá»­ dá»¥ng', 'CÃ²n tag', 'CÃ³ hÃ³a Ä‘Æ¡n']
    }
}
```

#### 5. `style-matcher.service.js`

Gá»£i Ã½ phá»‘i Ä‘á»“ theo style/dá»‹p.

#### 6. `add-to-cart.service.js`

**Flow: Context Extraction â†’ Product Lookup â†’ Confirmation**

```javascript
async handleAddToCart(query, extractedInfo, context) {
    // 1. Find product from conversation context (regex: **ProductName**)
    // 2. Fallback to vector search
    // 3. Get first available variant
    // 4. Return suggested_action for confirmation
}
```

---

### ðŸ“ **retrieval/**

| File | Chá»©c nÄƒng |
|------|-----------|
| `vector-search.service.js` | Pinecone vector similarity search |
| `reranking.service.js` | Cohere Rerank API |

**Vector Search:**

```javascript
searchProducts(query, { topK: 50 })
// â†’ Pinecone query with embedding
// â†’ Returns: [{ id, score, metadata: { product_id, product_name, proposition_text } }]
```

**Reranking:**

```javascript
rerankDocuments(query, documents, topN = 10)
// â†’ Cohere rerank-multilingual-v3.0
// â†’ Returns: [{ index, relevance_score }]
```

---

### ðŸ“ **generation/**

| File | Chá»©c nÄƒng |
|------|-----------|
| `prompt-builder.js` | XÃ¢y dá»±ng prompts cho cÃ¡c use cases |
| `response-generator.js` | Gá»i LLMProvider Ä‘á»ƒ generate |

**CoVe Prompt (Chain of Verification):**

```javascript
buildCoVePrompt(context, conversationHistory)
// Quy táº¯c:
// - CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« [Context]
// - KHÃ”NG bá»‹a Ä‘áº·t
// - KHÃ”NG emoji
// - GiÃ¡ dáº¡ng $XXX
// - DÃ¹ng **bold** cho tÃªn sáº£n pháº©m
```

---

### ðŸ“ **embeddings/**

| File | Chá»©c nÄƒng |
|------|-----------|
| `embedding.service.js` | OpenAI embeddings (text-embedding-3-small) |
| `proposition.service.js` | Chia product info thÃ nh chunks |

---

## Example Flows

### Flow 1: TÆ° váº¥n Sáº£n pháº©m

```
User: "tÃ¬m Ã¡o polo mÃ u wine red"
     â†“
1. hybridClassifyIntent â†’ "product_advice" (confidence: 0.8)
     â†“
2. productAdvice():
   2a. searchProducts("tÃ¬m Ã¡o polo mÃ u wine red", topK: 50)
   2b. findColorInQuery() â†’ { vi: "wine red", en: "wine red" }
   2c. MongoDB: ProductVariant.find({ color: /wine red/i })
   2d. rerankDocuments(query, propositions, top: 10)
   2e. Build context with color-matched products first
   2f. generateResponse(query, context)
     â†“
3. Response:
   {
     answer: "Dáº¡ cÃ³ báº¡n, mÃ¬nh cÃ³ **Cotton Polo Shirt** mÃ u Wine Red...",
     sources: [...],
     suggested_products: [{_id, name, variantId, mainImage, price}]
   }
```

### Flow 2: TÆ° váº¥n Size

```
User: "size M cÃ³ vá»«a khÃ´ng, cao 1m70 náº·ng 65kg"
     â†“
1. hybridClassifyIntent â†’ "size_recommendation"
   extracted_info: { height: 170, weight: 65 }
     â†“
2. sizeRecommendation():
   2a. Get product from context or search
   2b. Check Free Size â†’ If yes, return immediately
   2c. Build prompt with size chart
   2d. LLM â†’ JSON: { recommended_size: "M", reason: "..." }
   2e. Get variants of recommended size
     â†“
3. Response vá»›i suggested_action:
   {
     answer: "Vá»›i chiá»u cao 1m70 vÃ  cÃ¢n náº·ng 65kg, size M sáº½ vá»«a...",
     suggested_action: {
       type: "add_to_cart",
       variant_id: "...",
       product: {...}
     }
   }
     â†“
4. Client renders "CÃ³, thÃªm vÃ o giá»" / "KhÃ´ng, cáº£m Æ¡n" buttons
```

### Flow 3: Tra cá»©u ÄÆ¡n hÃ ng

```
User: "Ä‘Æ¡n hÃ ng cá»§a tÃ´i"
     â†“
1. hybridClassifyIntent â†’ "order_lookup"
     â†“
2. orderLookup(query, extractedInfo, userId):
   2a. LLM classify â†’ "list_all"
   2b. Check userId (logged in)
   2c. handleListAllOrders(userId)
   2d. Order.find({ user: userId }).sort({ createdAt: -1 }).limit(5)
     â†“
3. Response:
   {
     answer: "ÄÃ¢y lÃ  5 Ä‘Æ¡n hÃ ng gáº§n nháº¥t cá»§a báº¡n:\n\n1. #AB12CD34...",
     orders: [...]
   }
```

### Flow 4: Policy FAQ

```
User: "thanh toÃ¡n báº±ng crypto Ä‘Æ°á»£c khÃ´ng"
     â†“
1. quickIntentDetection â†’ "policy_faq" (confidence: 0.8)
   âš¡ Bypass LLM (high-confidence keyword match)
     â†“
2. policyFAQ():
   - isPaymentQuery = true (keyword: "crypto")
   - Return hardcoded payment info
     â†“
3. Response:
   {
     answer: "**PhÆ°Æ¡ng thá»©c thanh toÃ¡n táº¡i DEVENIR:**\n\n1. PayOS...\n2. NowPayments..."
   }
```

---

## Client-side Integration

```javascript
// ChatWindow.jsx
handleSendMessage(message)
     â†“
sendChatMessage(message, conversationHistory)
     â†“
Receive response: { intent, answer, suggested_action, suggested_products }
     â†“
ChatMessage.jsx
     â†“
// Render answer with markdown
// Render product cards if suggested_products
// Render action buttons if suggested_action
     â†“
handleYesClick() â†’ useAddToCart(variantId, quantity)
```

---

## Performance Optimizations

1. **Parallel Processing**: Intent classification + Context retrieval run in parallel
2. **Keyword Bypass**: High-confidence keywords skip LLM classification
3. **Color Cache**: Database colors cached for 1 hour
4. **Query Enrichment**: Short queries enriched with conversation context
5. **Selective Fields**: MongoDB queries use `.select()` for only needed fields

---

## Models Used

| Purpose | Model | Provider |
|---------|-------|----------|
| Chat Generation | gpt-4o-mini | OpenAI |
| Intent Classification | gpt-4o-mini (fast) | OpenAI |
| Embeddings | text-embedding-3-small | OpenAI |
| Reranking | rerank-multilingual-v3.0 | Cohere |
| Vector Database | Pinecone | Pinecone |
